{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa2124787128ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:04:15.048880600Z",
     "start_time": "2023-12-01T19:04:14.097823Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1624f0365a54c523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:12:50.373028800Z",
     "start_time": "2023-12-01T09:12:50.366946Z"
    }
   },
   "outputs": [],
   "source": [
    "app_token = \"Rl5BUiRawpr4H2LA9OQeKB47L\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c2feb6b97c6ff",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Download 311 data and 2015 tree cencus data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "330c4bf21749066b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: 2018-10-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_month_ranges(start_date, end_date):\n",
    "    current = start_date\n",
    "    temp = 0\n",
    "    while current < end_date:\n",
    "        temp += 1\n",
    "        month_end = current.replace(day=1) + timedelta(days=32)\n",
    "        month_end = month_end.replace(day=1) - timedelta(days=1) # 9 30\n",
    "        yield (current, month_end)\n",
    "        current = month_end + timedelta(days=1)\n",
    "        if temp == 100:\n",
    "            break\n",
    "\n",
    "#Set start date and end ate\n",
    "start_date = datetime(2018, 10, 1)\n",
    "end_date = datetime(2023, 9, 30)\n",
    "\n",
    "#Generate month's range\n",
    "month_ranges = list(generate_month_ranges(start_date, end_date))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T17:12:02.906961900Z",
     "start_time": "2023-11-29T17:12:02.897088700Z"
    }
   },
   "id": "3295db8a6395ef7d"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for the period: 2018-10-01 to 2018-10-31\n",
      "Downloading data for the period: 2018-11-01 to 2018-11-30\n",
      "Downloading data for the period: 2018-12-01 to 2018-12-31\n",
      "Downloading data for the period: 2019-01-01 to 2019-01-31\n",
      "Downloading data for the period: 2019-02-01 to 2019-02-28\n",
      "Downloading data for the period: 2019-03-01 to 2019-03-31\n",
      "Downloading data for the period: 2019-04-01 to 2019-04-30\n",
      "Downloading data for the period: 2019-05-01 to 2019-05-31\n",
      "Downloading data for the period: 2019-06-01 to 2019-06-30\n",
      "Downloading data for the period: 2019-07-01 to 2019-07-31\n",
      "Downloading data for the period: 2019-08-01 to 2019-08-31\n",
      "Downloading data for the period: 2019-09-01 to 2019-09-30\n",
      "Downloading data for the period: 2019-10-01 to 2019-10-31\n",
      "Downloading data for the period: 2019-11-01 to 2019-11-30\n",
      "Downloading data for the period: 2019-12-01 to 2019-12-31\n",
      "Downloading data for the period: 2020-01-01 to 2020-01-31\n",
      "Downloading data for the period: 2020-02-01 to 2020-02-29\n",
      "Downloading data for the period: 2020-03-01 to 2020-03-31\n",
      "Downloading data for the period: 2020-04-01 to 2020-04-30\n",
      "Downloading data for the period: 2020-05-01 to 2020-05-31\n",
      "Downloading data for the period: 2020-06-01 to 2020-06-30\n",
      "Downloading data for the period: 2020-07-01 to 2020-07-31\n",
      "Downloading data for the period: 2020-08-01 to 2020-08-31\n",
      "Downloading data for the period: 2020-09-01 to 2020-09-30\n",
      "Downloading data for the period: 2020-10-01 to 2020-10-31\n",
      "Downloading data for the period: 2020-11-01 to 2020-11-30\n",
      "Downloading data for the period: 2020-12-01 to 2020-12-31\n",
      "Downloading data for the period: 2021-01-01 to 2021-01-31\n",
      "Downloading data for the period: 2021-02-01 to 2021-02-28\n",
      "Downloading data for the period: 2021-03-01 to 2021-03-31\n",
      "Downloading data for the period: 2021-04-01 to 2021-04-30\n",
      "Downloading data for the period: 2021-05-01 to 2021-05-31\n",
      "Downloading data for the period: 2021-06-01 to 2021-06-30\n",
      "Downloading data for the period: 2021-07-01 to 2021-07-31\n",
      "Downloading data for the period: 2021-08-01 to 2021-08-31\n",
      "Downloading data for the period: 2021-09-01 to 2021-09-30\n",
      "Downloading data for the period: 2021-10-01 to 2021-10-31\n",
      "Downloading data for the period: 2021-11-01 to 2021-11-30\n",
      "Downloading data for the period: 2021-12-01 to 2021-12-31\n",
      "Downloading data for the period: 2022-01-01 to 2022-01-31\n",
      "Downloading data for the period: 2022-02-01 to 2022-02-28\n",
      "Downloading data for the period: 2022-03-01 to 2022-03-31\n",
      "Downloading data for the period: 2022-04-01 to 2022-04-30\n",
      "Downloading data for the period: 2022-05-01 to 2022-05-31\n",
      "Downloading data for the period: 2022-06-01 to 2022-06-30\n",
      "Downloading data for the period: 2022-07-01 to 2022-07-31\n",
      "Downloading data for the period: 2022-08-01 to 2022-08-31\n",
      "Downloading data for the period: 2022-09-01 to 2022-09-30\n",
      "Downloading data for the period: 2022-10-01 to 2022-10-31\n",
      "Downloading data for the period: 2022-11-01 to 2022-11-30\n",
      "Downloading data for the period: 2022-12-01 to 2022-12-31\n",
      "Downloading data for the period: 2023-01-01 to 2023-01-31\n",
      "Downloading data for the period: 2023-02-01 to 2023-02-28\n",
      "Downloading data for the period: 2023-03-01 to 2023-03-31\n",
      "Downloading data for the period: 2023-04-01 to 2023-04-30\n",
      "Downloading data for the period: 2023-05-01 to 2023-05-31\n",
      "Downloading data for the period: 2023-06-01 to 2023-06-30\n",
      "Downloading data for the period: 2023-07-01 to 2023-07-31\n",
      "Downloading data for the period: 2023-08-01 to 2023-08-31\n",
      "Downloading data for the period: 2023-09-01 to 2023-09-30\n",
      "Data download complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for start, end in month_ranges:\n",
    "    year = start.year\n",
    "    csv_file = f\"data/complaints_data_{year}.csv\"\n",
    "    print(f\"Downloading data for the period: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    query = f\"created_date between '{start.strftime('%Y-%m-%dT%H:%M:%S')}' and '{end.strftime('%Y-%m-%dT%H:%M:%S')}'\"\n",
    "    response = requests.get(\n",
    "        url=\"https://data.cityofnewyork.us/resource/erm2-nwe9.json\",\n",
    "        params={\"$$app_token\": app_token, \"$where\": query, \"$limit\": 999999,\n",
    "                \"$select\": \"unique_key, created_date, closed_date, agency,  complaint_type, descriptor, location_type, incident_zip, latitude, longitude, borough\"\n",
    "                }\n",
    "    )\n",
    "    data = response.json()\n",
    "    batch_df = pd.DataFrame(data)\n",
    "\n",
    "    # 根据年份写入或追加到对应的CSV文件\n",
    "    mode = 'a' if os.path.exists(csv_file) else 'w'\n",
    "    batch_df.to_csv(csv_file, mode=mode, index=False, header=not os.path.exists(csv_file))\n",
    "\n",
    "print(\"Data download complete.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T17:24:11.674616400Z",
     "start_time": "2023-11-29T17:12:24.126641100Z"
    }
   },
   "id": "83354ebeb00066c5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d3be5437f18791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T12:28:17.404288300Z",
     "start_time": "2023-11-24T12:27:10.545855600Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_data = requests.get(url=\"https://data.cityofnewyork.us/resource/5rq2-4hqu.json\",\n",
    "                         params={\"$$app_token\": app_token, \"$limit\": 99999999999999999999}).json()\n",
    "tree_df = pd.DataFrame(tree_data)\n",
    "tree_df.to_csv(\"data/tree.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Data Cleaning & Filtering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b696afcf38df01b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1 311 Data Cleaning & Filtering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df2cdda1a5658915"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def clean_311_data(datafile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    #Add fix_zip function\n",
    "    def fix_zip(input_zip):\n",
    "        try:\n",
    "            input_zip = int(float(input_zip))\n",
    "        except:\n",
    "            try:\n",
    "                input_zip = int(input_zip.split('-')[0])\n",
    "            except:\n",
    "                return np.NaN\n",
    "        if input_zip < 10000 or input_zip > 12000:\n",
    "            return np.NaN\n",
    "        return str(input_zip)\n",
    "\n",
    "    #Read the file\n",
    "    df = pd.read_csv(datafile, low_memory=False)\n",
    "\n",
    "    #fix the zip\n",
    "    df['incident_zip'] = df['incident_zip'].apply(fix_zip)\n",
    "\n",
    "    df = df.dropna(how='any')\n",
    "\n",
    "    #get rid of unspecified boroughs\n",
    "    df = df[df['borough'] != 'Unspecified']\n",
    "\n",
    "    df['latitude'] = df['latitude'].astype('float64')\n",
    "    df['longitude'] = df['longitude'].astype('float64')\n",
    "\n",
    "    #Converts the 'closed_date','created_date' column into a datetime object\n",
    "    df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "    df['closed_date'] = pd.to_datetime(df['closed_date'])\n",
    "    # Convert longitude and latitude to a 'geometry' column for geopandas\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "    # Create a GeoDataFrame and set the coordinate reference system (CRS) to WGS84 (EPSG:4326)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:12:56.581850Z",
     "start_time": "2023-12-01T09:12:56.577389900Z"
    }
   },
   "id": "e56f7fc9c3685163"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 338343 entries, 0 to 454962\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   unique_key      338343 non-null  int64         \n",
      " 1   created_date    338343 non-null  datetime64[ns]\n",
      " 2   closed_date     338343 non-null  datetime64[ns]\n",
      " 3   agency          338343 non-null  object        \n",
      " 4   complaint_type  338343 non-null  object        \n",
      " 5   descriptor      338343 non-null  object        \n",
      " 6   location_type   338343 non-null  object        \n",
      " 7   incident_zip    338343 non-null  object        \n",
      " 8   latitude        338343 non-null  float64       \n",
      " 9   longitude       338343 non-null  float64       \n",
      " 10  borough         338343 non-null  object        \n",
      " 11  geometry        338343 non-null  geometry      \n",
      "dtypes: datetime64[ns](2), float64(2), geometry(1), int64(1), object(6)\n",
      "memory usage: 33.6+ MB\n"
     ]
    }
   ],
   "source": [
    "complaints_2018 = clean_311_data('data/complaints_data_2018.csv')\n",
    "complaints_2018.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:14:45.759399500Z",
     "start_time": "2023-12-01T09:14:38.818671100Z"
    }
   },
   "id": "715b71bd9e15fcd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.2 2015 Tree census Data Cleaning & Filtering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9a118f36cd1e40d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tree = pd.read_csv('data/tree.csv', usecols=['tree_id', 'the_geom',   'spc_common', 'status', 'health', 'zipcode', 'boroname', 'latitude', 'longitude'])\n",
    "tree.to_csv('data/tree_data.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:15:35.515364500Z",
     "start_time": "2023-12-01T09:15:31.051789500Z"
    }
   },
   "id": "5d3f4ec5dfdeeffc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def clean_tree_data(datafile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "\n",
    "    # Add fix_zip function\n",
    "    def fix_zip(input_zip):\n",
    "        try:\n",
    "            input_zip = int(float(input_zip))\n",
    "        except:\n",
    "            try:\n",
    "                input_zip = int(input_zip.split('-')[0]) \n",
    "            except:\n",
    "                return np.NaN\n",
    "        if input_zip < 10000 or input_zip > 12000:\n",
    "            return np.NaN\n",
    "        return str(input_zip)\n",
    "\n",
    "    # Read the file\n",
    "    df = pd.read_csv(datafile)\n",
    "\n",
    "    # Fix the zip\n",
    "    df['zipcode'] = df['zipcode'].apply(fix_zip)\n",
    "\n",
    "    df = df.dropna(how='any')\n",
    "\n",
    "    # Make some columns name readable\n",
    "    df.rename(columns={'the_geom': 'geometry', 'spc_common': 'species', 'boroname': 'borough'}, inplace=True)\n",
    "\n",
    "    # Convert longitude and latitude to a 'geometry' column for geopandas\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "    # Create a GeoDataFrame and set the coordinate reference system (CRS) to WGS84 (EPSG:4326)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:15:42.837127600Z",
     "start_time": "2023-12-01T09:15:42.831783500Z"
    }
   },
   "id": "6fa2f0e9bd8bfbdb"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 651235 entries, 0 to 683787\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype   \n",
      "---  ------     --------------   -----   \n",
      " 0   tree_id    651235 non-null  int64   \n",
      " 1   geometry   651235 non-null  geometry\n",
      " 2   status     651235 non-null  object  \n",
      " 3   health     651235 non-null  object  \n",
      " 4   species    651235 non-null  object  \n",
      " 5   zipcode    651235 non-null  object  \n",
      " 6   borough    651235 non-null  object  \n",
      " 7   latitude   651235 non-null  float64 \n",
      " 8   longitude  651235 non-null  float64 \n",
      "dtypes: float64(2), geometry(1), int64(1), object(5)\n",
      "memory usage: 49.7+ MB\n"
     ]
    }
   ],
   "source": [
    "tree = clean_tree_data('data/tree_data.csv')\n",
    "tree.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:16:34.246875400Z",
     "start_time": "2023-12-01T09:16:24.041320500Z"
    }
   },
   "id": "d8e5b3ff515cb203"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.3 Zillow Data Cleaning & Filtering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce46dd6154979aed"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def clean_zillow_data(datafile):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(datafile, low_memory=False)\n",
    "\n",
    "    df = df[df['City'] == 'New York']\n",
    "\n",
    "    # Select the 'RegionName' and 'CountyName' columns and store them in df1\n",
    "    df1 = df[['RegionName', 'CountyName']]\n",
    "    # Select all columns from '2018-09-30' onwards and store them in df2\n",
    "    df2 = df.loc[:, '2018-09-30':]\n",
    "\n",
    "    # Concatenate df1 and df2 along the columns (axis=1)\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    # Make columns' name more readable\n",
    "    df.rename(columns={'RegionName': 'zipcode', 'CountyName': 'county'}, inplace=True)\n",
    "\n",
    "    # Convert the 'zipcode' column to a string data type\n",
    "    df['zipcode'] = df['zipcode'].astype(str)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:16:57.183094200Z",
     "start_time": "2023-12-01T09:16:57.167002500Z"
    }
   },
   "id": "11cff05825dba5c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 145 entries, 4 to 6721\n",
      "Data columns (total 63 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   zipcode     145 non-null    object \n",
      " 1   county      145 non-null    object \n",
      " 2   2018-09-30  76 non-null     float64\n",
      " 3   2018-10-31  76 non-null     float64\n",
      " 4   2018-11-30  76 non-null     float64\n",
      " 5   2018-12-31  75 non-null     float64\n",
      " 6   2019-01-31  77 non-null     float64\n",
      " 7   2019-02-28  77 non-null     float64\n",
      " 8   2019-03-31  79 non-null     float64\n",
      " 9   2019-04-30  79 non-null     float64\n",
      " 10  2019-05-31  79 non-null     float64\n",
      " 11  2019-06-30  79 non-null     float64\n",
      " 12  2019-07-31  79 non-null     float64\n",
      " 13  2019-08-31  79 non-null     float64\n",
      " 14  2019-09-30  79 non-null     float64\n",
      " 15  2019-10-31  79 non-null     float64\n",
      " 16  2019-11-30  79 non-null     float64\n",
      " 17  2019-12-31  79 non-null     float64\n",
      " 18  2020-01-31  81 non-null     float64\n",
      " 19  2020-02-29  81 non-null     float64\n",
      " 20  2020-03-31  81 non-null     float64\n",
      " 21  2020-04-30  82 non-null     float64\n",
      " 22  2020-05-31  88 non-null     float64\n",
      " 23  2020-06-30  88 non-null     float64\n",
      " 24  2020-07-31  90 non-null     float64\n",
      " 25  2020-08-31  87 non-null     float64\n",
      " 26  2020-09-30  88 non-null     float64\n",
      " 27  2020-10-31  92 non-null     float64\n",
      " 28  2020-11-30  92 non-null     float64\n",
      " 29  2020-12-31  93 non-null     float64\n",
      " 30  2021-01-31  96 non-null     float64\n",
      " 31  2021-02-28  97 non-null     float64\n",
      " 32  2021-03-31  98 non-null     float64\n",
      " 33  2021-04-30  99 non-null     float64\n",
      " 34  2021-05-31  99 non-null     float64\n",
      " 35  2021-06-30  99 non-null     float64\n",
      " 36  2021-07-31  99 non-null     float64\n",
      " 37  2021-08-31  99 non-null     float64\n",
      " 38  2021-09-30  99 non-null     float64\n",
      " 39  2021-10-31  101 non-null    float64\n",
      " 40  2021-11-30  101 non-null    float64\n",
      " 41  2021-12-31  104 non-null    float64\n",
      " 42  2022-01-31  107 non-null    float64\n",
      " 43  2022-02-28  107 non-null    float64\n",
      " 44  2022-03-31  113 non-null    float64\n",
      " 45  2022-04-30  114 non-null    float64\n",
      " 46  2022-05-31  116 non-null    float64\n",
      " 47  2022-06-30  118 non-null    float64\n",
      " 48  2022-07-31  118 non-null    float64\n",
      " 49  2022-08-31  119 non-null    float64\n",
      " 50  2022-09-30  118 non-null    float64\n",
      " 51  2022-10-31  119 non-null    float64\n",
      " 52  2022-11-30  120 non-null    float64\n",
      " 53  2022-12-31  122 non-null    float64\n",
      " 54  2023-01-31  121 non-null    float64\n",
      " 55  2023-02-28  124 non-null    float64\n",
      " 56  2023-03-31  125 non-null    float64\n",
      " 57  2023-04-30  126 non-null    float64\n",
      " 58  2023-05-31  130 non-null    float64\n",
      " 59  2023-06-30  131 non-null    float64\n",
      " 60  2023-07-31  133 non-null    float64\n",
      " 61  2023-08-31  138 non-null    float64\n",
      " 62  2023-09-30  145 non-null    float64\n",
      "dtypes: float64(61), object(2)\n",
      "memory usage: 72.5+ KB\n"
     ]
    }
   ],
   "source": [
    "zillow = clean_zillow_data('data/zillow_rent_data.csv')\n",
    "zillow.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:17:34.751980800Z",
     "start_time": "2023-12-01T09:17:34.689938800Z"
    }
   },
   "id": "c2152708328b6953"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.4 Zipcode data Cleaning & Filtering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea1ccceb0d7b6b24"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def clean_zipcode_data(datafile):\n",
    "    import geopandas as gpd\n",
    "\n",
    "    gdf = gpd.read_file(datafile)\n",
    "    \n",
    "    gdf.crs = 'EPSG:4326'\n",
    "    \n",
    "    gdf = gdf.to_crs('EPSG:4326')\n",
    "    #Select specific columns\n",
    "    gdf = gdf[['ZIPCODE', 'POPULATION', 'geometry' ]]\n",
    "\n",
    "    gdf.rename(columns={'ZIPCODE':'zipcode', 'POPULATION':'population'}, inplace=True)\n",
    "\n",
    "    return gdf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T19:08:17.191178Z",
     "start_time": "2023-12-01T19:08:17.182922700Z"
    }
   },
   "id": "a929ad3b8b67829"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   zipcode     263 non-null    object  \n",
      " 1   population  263 non-null    float64 \n",
      " 2   geometry    263 non-null    geometry\n",
      "dtypes: float64(1), geometry(1), object(1)\n",
      "memory usage: 6.3+ KB\n"
     ]
    }
   ],
   "source": [
    "zipcode = clean_zipcode_data('data/nyc_zipcodes.shp')\n",
    "zipcode.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T19:08:19.834285600Z",
     "start_time": "2023-12-01T19:08:19.616224700Z"
    }
   },
   "id": "4d48f7e9f76065e4"
  },
  {
   "cell_type": "markdown",
   "id": "16dea2f1da9eaed5",
   "metadata": {},
   "source": [
    "# Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dbefcc832d105dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T01:55:53.627984200Z",
     "start_time": "2023-11-29T01:55:53.586770400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'createdb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'psql' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!createdb FINAL_PROJECT\n",
    "!psql --dbname FINAL_PROJECT -c 'CREATE EXTENSION postgis;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63488583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T03:08:38.188433400Z",
     "start_time": "2023-11-29T03:08:38.174506500Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "796567f058261f19",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T03:08:38.424507500Z",
     "start_time": "2023-11-29T03:08:38.354942700Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=final_project user=postgres password=123456\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bcb6eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T03:08:38.547727600Z",
     "start_time": "2023-11-29T03:08:38.515450300Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('schema.sql', 'w') as f:\n",
    "    command = \"\"\"\n",
    "        CREATE TABLE zip_codes (\n",
    "            zip_code Integer PRIMARY KEY,\n",
    "            neighborhood TEXT,\n",
    "            borough TEXT,\n",
    "            geometry GEOMETRY(Point, 4326)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE complaints (\n",
    "            complaint_id Integer PRIMARY KEY,\n",
    "            created_date TIMESTAMP,\n",
    "            complaint_type TEXT,\n",
    "            descriptor TEXT,\n",
    "            zip_code Integer REFERENCES zip_codes(zip_code),\n",
    "            latitude FLOAT,\n",
    "            longitude FLOAT,\n",
    "            geometry GEOMETRY(Point, 4326)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE trees (\n",
    "            tree_id Integer PRIMARY KEY,\n",
    "            species TEXT,\n",
    "            diameter_inches FLOAT,\n",
    "            health TEXT,\n",
    "            zip_code Integer REFERENCES zip_codes(zip_code),\n",
    "            latitude FLOAT,\n",
    "            longitude FLOAT,\n",
    "            geometry GEOMETRY(Point, 4326)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE average_rents (\n",
    "            zip_code Integer PRIMARY KEY,\n",
    "            year INT,\n",
    "            avg_rent DECIMAL\n",
    "        );\n",
    "    \"\"\"\n",
    "    f.write(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "595eaa9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T03:08:39.276523Z",
     "start_time": "2023-11-29T03:08:39.235973700Z"
    }
   },
   "outputs": [],
   "source": [
    "cur.execute(command)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c6bc5c024a8c2",
   "metadata": {},
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a02c5e133f921d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18ffd1bb99075ea9",
   "metadata": {},
   "source": [
    "# Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af7d548eed2ae8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-24T11:43:13.539677300Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

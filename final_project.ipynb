{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa2124787128ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:04:15.048880600Z",
     "start_time": "2023-12-01T19:04:14.097823Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1624f0365a54c523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:12:50.373028800Z",
     "start_time": "2023-12-01T09:12:50.366946Z"
    }
   },
   "outputs": [],
   "source": [
    "app_token = \"Rl5BUiRawpr4H2LA9OQeKB47L\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c2feb6b97c6ff",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c4bf21749066b",
   "metadata": {},
   "source": [
    "## 1.1 Download 311 data and 2015 tree cencus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3295db8a6395ef7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T17:12:02.906961900Z",
     "start_time": "2023-11-29T17:12:02.897088700Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_month_ranges(start_date, end_date):\n",
    "    current = start_date\n",
    "    temp = 0\n",
    "    while current < end_date:\n",
    "        temp += 1\n",
    "        month_end = current.replace(day=1) + timedelta(days=32)\n",
    "        month_end = month_end.replace(day=1) - timedelta(days=1) # 9 30\n",
    "        yield (current, month_end)\n",
    "        current = month_end + timedelta(days=1)\n",
    "        if temp == 100:\n",
    "            break\n",
    "\n",
    "#Set start date and end ate\n",
    "start_date = datetime(2018, 10, 1)\n",
    "end_date = datetime(2023, 9, 30)\n",
    "\n",
    "#Generate month's range\n",
    "month_ranges = list(generate_month_ranges(start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83354ebeb00066c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T17:24:11.674616400Z",
     "start_time": "2023-11-29T17:12:24.126641100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for the period: 2018-10-01 to 2018-10-31\n",
      "Downloading data for the period: 2018-11-01 to 2018-11-30\n",
      "Downloading data for the period: 2018-12-01 to 2018-12-31\n",
      "Downloading data for the period: 2019-01-01 to 2019-01-31\n",
      "Downloading data for the period: 2019-02-01 to 2019-02-28\n",
      "Downloading data for the period: 2019-03-01 to 2019-03-31\n",
      "Downloading data for the period: 2019-04-01 to 2019-04-30\n",
      "Downloading data for the period: 2019-05-01 to 2019-05-31\n",
      "Downloading data for the period: 2019-06-01 to 2019-06-30\n",
      "Downloading data for the period: 2019-07-01 to 2019-07-31\n",
      "Downloading data for the period: 2019-08-01 to 2019-08-31\n",
      "Downloading data for the period: 2019-09-01 to 2019-09-30\n",
      "Downloading data for the period: 2019-10-01 to 2019-10-31\n",
      "Downloading data for the period: 2019-11-01 to 2019-11-30\n",
      "Downloading data for the period: 2019-12-01 to 2019-12-31\n",
      "Downloading data for the period: 2020-01-01 to 2020-01-31\n",
      "Downloading data for the period: 2020-02-01 to 2020-02-29\n",
      "Downloading data for the period: 2020-03-01 to 2020-03-31\n",
      "Downloading data for the period: 2020-04-01 to 2020-04-30\n",
      "Downloading data for the period: 2020-05-01 to 2020-05-31\n",
      "Downloading data for the period: 2020-06-01 to 2020-06-30\n",
      "Downloading data for the period: 2020-07-01 to 2020-07-31\n",
      "Downloading data for the period: 2020-08-01 to 2020-08-31\n",
      "Downloading data for the period: 2020-09-01 to 2020-09-30\n",
      "Downloading data for the period: 2020-10-01 to 2020-10-31\n",
      "Downloading data for the period: 2020-11-01 to 2020-11-30\n",
      "Downloading data for the period: 2020-12-01 to 2020-12-31\n",
      "Downloading data for the period: 2021-01-01 to 2021-01-31\n",
      "Downloading data for the period: 2021-02-01 to 2021-02-28\n",
      "Downloading data for the period: 2021-03-01 to 2021-03-31\n",
      "Downloading data for the period: 2021-04-01 to 2021-04-30\n",
      "Downloading data for the period: 2021-05-01 to 2021-05-31\n",
      "Downloading data for the period: 2021-06-01 to 2021-06-30\n",
      "Downloading data for the period: 2021-07-01 to 2021-07-31\n",
      "Downloading data for the period: 2021-08-01 to 2021-08-31\n",
      "Downloading data for the period: 2021-09-01 to 2021-09-30\n",
      "Downloading data for the period: 2021-10-01 to 2021-10-31\n",
      "Downloading data for the period: 2021-11-01 to 2021-11-30\n",
      "Downloading data for the period: 2021-12-01 to 2021-12-31\n",
      "Downloading data for the period: 2022-01-01 to 2022-01-31\n",
      "Downloading data for the period: 2022-02-01 to 2022-02-28\n",
      "Downloading data for the period: 2022-03-01 to 2022-03-31\n",
      "Downloading data for the period: 2022-04-01 to 2022-04-30\n",
      "Downloading data for the period: 2022-05-01 to 2022-05-31\n",
      "Downloading data for the period: 2022-06-01 to 2022-06-30\n",
      "Downloading data for the period: 2022-07-01 to 2022-07-31\n",
      "Downloading data for the period: 2022-08-01 to 2022-08-31\n",
      "Downloading data for the period: 2022-09-01 to 2022-09-30\n",
      "Downloading data for the period: 2022-10-01 to 2022-10-31\n",
      "Downloading data for the period: 2022-11-01 to 2022-11-30\n",
      "Downloading data for the period: 2022-12-01 to 2022-12-31\n",
      "Downloading data for the period: 2023-01-01 to 2023-01-31\n",
      "Downloading data for the period: 2023-02-01 to 2023-02-28\n",
      "Downloading data for the period: 2023-03-01 to 2023-03-31\n",
      "Downloading data for the period: 2023-04-01 to 2023-04-30\n",
      "Downloading data for the period: 2023-05-01 to 2023-05-31\n",
      "Downloading data for the period: 2023-06-01 to 2023-06-30\n",
      "Downloading data for the period: 2023-07-01 to 2023-07-31\n",
      "Downloading data for the period: 2023-08-01 to 2023-08-31\n",
      "Downloading data for the period: 2023-09-01 to 2023-09-30\n",
      "Data download complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for start, end in month_ranges:\n",
    "    year = start.year\n",
    "    csv_file = f\"data/complaints_data_{year}.csv\"\n",
    "    print(f\"Downloading data for the period: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    query = f\"created_date between '{start.strftime('%Y-%m-%dT%H:%M:%S')}' and '{end.strftime('%Y-%m-%dT%H:%M:%S')}'\"\n",
    "    response = requests.get(\n",
    "        url=\"https://data.cityofnewyork.us/resource/erm2-nwe9.json\",\n",
    "        params={\"$$app_token\": app_token, \"$where\": query, \"$limit\": 999999,\n",
    "                \"$select\": \"unique_key, created_date, closed_date, agency,  complaint_type, descriptor, location_type, incident_zip, latitude, longitude, borough\"\n",
    "                }\n",
    "    )\n",
    "    data = response.json()\n",
    "    batch_df = pd.DataFrame(data)\n",
    "\n",
    "    # 根据年份写入或追加到对应的CSV文件\n",
    "    mode = 'a' if os.path.exists(csv_file) else 'w'\n",
    "    batch_df.to_csv(csv_file, mode=mode, index=False, header=not os.path.exists(csv_file))\n",
    "\n",
    "print(\"Data download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d3be5437f18791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T12:28:17.404288300Z",
     "start_time": "2023-11-24T12:27:10.545855600Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_data = requests.get(url=\"https://data.cityofnewyork.us/resource/5rq2-4hqu.json\",\n",
    "                         params={\"$$app_token\": app_token, \"$limit\": 99999999999999999999}).json()\n",
    "tree_df = pd.DataFrame(tree_data)\n",
    "tree_df.to_csv(\"data/tree.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b696afcf38df01b",
   "metadata": {},
   "source": [
    "## 1.2 Data Cleaning & Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cdda1a5658915",
   "metadata": {},
   "source": [
    "### 1.2.1 311 Data Cleaning & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56f7fc9c3685163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:12:56.581850Z",
     "start_time": "2023-12-01T09:12:56.577389900Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_311_data(datafile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    #Add fix_zip function\n",
    "    def fix_zip(input_zip):\n",
    "        try:\n",
    "            input_zip = int(float(input_zip))\n",
    "        except:\n",
    "            try:\n",
    "                input_zip = int(input_zip.split('-')[0])\n",
    "            except:\n",
    "                return np.NaN\n",
    "        if input_zip < 10000 or input_zip > 12000:\n",
    "            return np.NaN\n",
    "        return str(input_zip)\n",
    "\n",
    "    #Read the file\n",
    "    df = pd.read_csv(datafile, low_memory=False)\n",
    "\n",
    "    #fix the zip\n",
    "    df['incident_zip'] = df['incident_zip'].apply(fix_zip)\n",
    "\n",
    "    df = df.dropna(how='any')\n",
    "\n",
    "    #get rid of unspecified boroughs\n",
    "    df = df[df['borough'] != 'Unspecified']\n",
    "\n",
    "    df['latitude'] = df['latitude'].astype('float64')\n",
    "    df['longitude'] = df['longitude'].astype('float64')\n",
    "\n",
    "    #Converts the 'closed_date','created_date' column into a datetime object\n",
    "    df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "    df['closed_date'] = pd.to_datetime(df['closed_date'])\n",
    "    # Convert longitude and latitude to a 'geometry' column for geopandas\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "    # Create a GeoDataFrame and set the coordinate reference system (CRS) to WGS84 (EPSG:4326)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715b71bd9e15fcd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:14:45.759399500Z",
     "start_time": "2023-12-01T09:14:38.818671100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 1513084 entries, 0 to 2022503\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   unique_key      1513084 non-null  int64         \n",
      " 1   created_date    1513084 non-null  datetime64[ns]\n",
      " 2   closed_date     1513084 non-null  datetime64[ns]\n",
      " 3   agency          1513084 non-null  object        \n",
      " 4   complaint_type  1513084 non-null  object        \n",
      " 5   descriptor      1513084 non-null  object        \n",
      " 6   location_type   1513084 non-null  object        \n",
      " 7   incident_zip    1513084 non-null  object        \n",
      " 8   latitude        1513084 non-null  float64       \n",
      " 9   longitude       1513084 non-null  float64       \n",
      " 10  borough         1513084 non-null  object        \n",
      " 11  geometry        1513084 non-null  geometry      \n",
      "dtypes: datetime64[ns](2), float64(2), geometry(1), int64(1), object(6)\n",
      "memory usage: 150.1+ MB\n"
     ]
    }
   ],
   "source": [
    "complaints_2018 = clean_311_data('data/complaints_data_2018.csv')\n",
    "complaints_2018.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a118f36cd1e40d",
   "metadata": {},
   "source": [
    "### 1.2.2 2015 Tree census Data Cleaning & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3f4ec5dfdeeffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:15:35.515364500Z",
     "start_time": "2023-12-01T09:15:31.051789500Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = pd.read_csv('data/tree.csv', usecols=['tree_id', 'the_geom',   'spc_common', 'status', 'health', 'zipcode', 'boroname', 'latitude', 'longitude'])\n",
    "tree.to_csv('data/tree_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa2f0e9bd8bfbdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:15:42.837127600Z",
     "start_time": "2023-12-01T09:15:42.831783500Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_tree_data(datafile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "\n",
    "    # Add fix_zip function\n",
    "    def fix_zip(input_zip):\n",
    "        try:\n",
    "            input_zip = int(float(input_zip))\n",
    "        except:\n",
    "            try:\n",
    "                input_zip = int(input_zip.split('-')[0]) \n",
    "            except:\n",
    "                return np.NaN\n",
    "        if input_zip < 10000 or input_zip > 12000:\n",
    "            return np.NaN\n",
    "        return str(input_zip)\n",
    "\n",
    "    # Read the file\n",
    "    df = pd.read_csv(datafile)\n",
    "\n",
    "    # Fix the zip\n",
    "    df['zipcode'] = df['zipcode'].apply(fix_zip)\n",
    "\n",
    "    df = df.dropna(how='any')\n",
    "\n",
    "    # Make some columns name readable\n",
    "    df.rename(columns={'the_geom': 'geometry', 'spc_common': 'species', 'boroname': 'borough'}, inplace=True)\n",
    "\n",
    "    # Convert longitude and latitude to a 'geometry' column for geopandas\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "    # Create a GeoDataFrame and set the coordinate reference system (CRS) to WGS84 (EPSG:4326)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8e5b3ff515cb203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:16:34.246875400Z",
     "start_time": "2023-12-01T09:16:24.041320500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 651235 entries, 0 to 683787\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype   \n",
      "---  ------     --------------   -----   \n",
      " 0   tree_id    651235 non-null  int64   \n",
      " 1   geometry   651235 non-null  geometry\n",
      " 2   status     651235 non-null  object  \n",
      " 3   health     651235 non-null  object  \n",
      " 4   species    651235 non-null  object  \n",
      " 5   zipcode    651235 non-null  object  \n",
      " 6   borough    651235 non-null  object  \n",
      " 7   latitude   651235 non-null  float64 \n",
      " 8   longitude  651235 non-null  float64 \n",
      "dtypes: float64(2), geometry(1), int64(1), object(5)\n",
      "memory usage: 49.7+ MB\n"
     ]
    }
   ],
   "source": [
    "tree = clean_tree_data('data/tree_data.csv')\n",
    "tree.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46dd6154979aed",
   "metadata": {},
   "source": [
    "### 1.2.3 Zillow Data Cleaning & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11cff05825dba5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:16:57.183094200Z",
     "start_time": "2023-12-01T09:16:57.167002500Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_zillow_data(datafile):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(datafile, low_memory=False)\n",
    "\n",
    "    df = df[df['City'] == 'New York']\n",
    "\n",
    "    # Select the 'RegionName' and 'CountyName' columns and store them in df1\n",
    "    df1 = df[['RegionName', 'CountyName']]\n",
    "    # Select all columns from '2018-09-30' onwards and store them in df2\n",
    "    df2 = df.loc[:, '2018-09-30':]\n",
    "\n",
    "    # Concatenate df1 and df2 along the columns (axis=1)\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    # Make columns' name more readable\n",
    "    df.rename(columns={'RegionName': 'zipcode', 'CountyName': 'county'}, inplace=True)\n",
    "\n",
    "    # Convert the 'zipcode' column to a string data type\n",
    "    df['zipcode'] = df['zipcode'].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2152708328b6953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:17:34.751980800Z",
     "start_time": "2023-12-01T09:17:34.689938800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 145 entries, 4 to 6721\n",
      "Data columns (total 63 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   zipcode     145 non-null    object \n",
      " 1   county      145 non-null    object \n",
      " 2   2018-09-30  76 non-null     float64\n",
      " 3   2018-10-31  76 non-null     float64\n",
      " 4   2018-11-30  76 non-null     float64\n",
      " 5   2018-12-31  75 non-null     float64\n",
      " 6   2019-01-31  77 non-null     float64\n",
      " 7   2019-02-28  77 non-null     float64\n",
      " 8   2019-03-31  79 non-null     float64\n",
      " 9   2019-04-30  79 non-null     float64\n",
      " 10  2019-05-31  79 non-null     float64\n",
      " 11  2019-06-30  79 non-null     float64\n",
      " 12  2019-07-31  79 non-null     float64\n",
      " 13  2019-08-31  79 non-null     float64\n",
      " 14  2019-09-30  79 non-null     float64\n",
      " 15  2019-10-31  79 non-null     float64\n",
      " 16  2019-11-30  79 non-null     float64\n",
      " 17  2019-12-31  79 non-null     float64\n",
      " 18  2020-01-31  81 non-null     float64\n",
      " 19  2020-02-29  81 non-null     float64\n",
      " 20  2020-03-31  81 non-null     float64\n",
      " 21  2020-04-30  82 non-null     float64\n",
      " 22  2020-05-31  88 non-null     float64\n",
      " 23  2020-06-30  88 non-null     float64\n",
      " 24  2020-07-31  90 non-null     float64\n",
      " 25  2020-08-31  87 non-null     float64\n",
      " 26  2020-09-30  88 non-null     float64\n",
      " 27  2020-10-31  92 non-null     float64\n",
      " 28  2020-11-30  92 non-null     float64\n",
      " 29  2020-12-31  93 non-null     float64\n",
      " 30  2021-01-31  96 non-null     float64\n",
      " 31  2021-02-28  97 non-null     float64\n",
      " 32  2021-03-31  98 non-null     float64\n",
      " 33  2021-04-30  99 non-null     float64\n",
      " 34  2021-05-31  99 non-null     float64\n",
      " 35  2021-06-30  99 non-null     float64\n",
      " 36  2021-07-31  99 non-null     float64\n",
      " 37  2021-08-31  99 non-null     float64\n",
      " 38  2021-09-30  99 non-null     float64\n",
      " 39  2021-10-31  101 non-null    float64\n",
      " 40  2021-11-30  101 non-null    float64\n",
      " 41  2021-12-31  104 non-null    float64\n",
      " 42  2022-01-31  107 non-null    float64\n",
      " 43  2022-02-28  107 non-null    float64\n",
      " 44  2022-03-31  113 non-null    float64\n",
      " 45  2022-04-30  114 non-null    float64\n",
      " 46  2022-05-31  116 non-null    float64\n",
      " 47  2022-06-30  118 non-null    float64\n",
      " 48  2022-07-31  118 non-null    float64\n",
      " 49  2022-08-31  119 non-null    float64\n",
      " 50  2022-09-30  118 non-null    float64\n",
      " 51  2022-10-31  119 non-null    float64\n",
      " 52  2022-11-30  120 non-null    float64\n",
      " 53  2022-12-31  122 non-null    float64\n",
      " 54  2023-01-31  121 non-null    float64\n",
      " 55  2023-02-28  124 non-null    float64\n",
      " 56  2023-03-31  125 non-null    float64\n",
      " 57  2023-04-30  126 non-null    float64\n",
      " 58  2023-05-31  130 non-null    float64\n",
      " 59  2023-06-30  131 non-null    float64\n",
      " 60  2023-07-31  133 non-null    float64\n",
      " 61  2023-08-31  138 non-null    float64\n",
      " 62  2023-09-30  145 non-null    float64\n",
      "dtypes: float64(61), object(2)\n",
      "memory usage: 72.5+ KB\n"
     ]
    }
   ],
   "source": [
    "zillow = clean_zillow_data('data/zillow_rent_data.csv')\n",
    "zillow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ccceb0d7b6b24",
   "metadata": {},
   "source": [
    "### 1.2.4 Zipcode data Cleaning & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a929ad3b8b67829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:08:17.191178Z",
     "start_time": "2023-12-01T19:08:17.182922700Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_zipcode_data(datafile):\n",
    "    import geopandas as gpd\n",
    "\n",
    "    gdf = gpd.read_file(datafile)\n",
    "    \n",
    "    gdf.crs = 'EPSG:4326'\n",
    "    \n",
    "    gdf = gdf.to_crs('EPSG:4326')\n",
    "    #Select specific columns\n",
    "    gdf = gdf[['ZIPCODE', 'POPULATION', 'geometry' ]]\n",
    "\n",
    "    gdf.rename(columns={'ZIPCODE':'zipcode', 'POPULATION':'population'}, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d48f7e9f76065e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:08:19.834285600Z",
     "start_time": "2023-12-01T19:08:19.616224700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   zipcode     263 non-null    object  \n",
      " 1   population  263 non-null    float64 \n",
      " 2   geometry    263 non-null    geometry\n",
      "dtypes: float64(1), geometry(1), object(1)\n",
      "memory usage: 6.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>population</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>18681.0</td>\n",
       "      <td>POLYGON ((1038098.25187 188138.38001, 1038141....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>62426.0</td>\n",
       "      <td>POLYGON ((1001613.71296 186926.43952, 1002314....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>83866.0</td>\n",
       "      <td>POLYGON ((1011174.27554 183696.33771, 1011373....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>56527.0</td>\n",
       "      <td>POLYGON ((995908.36545 183617.61280, 996522.84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>72280.0</td>\n",
       "      <td>POLYGON ((991997.11343 176307.49586, 992042.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>10310</td>\n",
       "      <td>25003.0</td>\n",
       "      <td>POLYGON ((950767.50659 172848.96866, 950787.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>11693</td>\n",
       "      <td>11052.0</td>\n",
       "      <td>POLYGON ((1028453.99491 167153.40984, 1027813....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>11249</td>\n",
       "      <td>28481.0</td>\n",
       "      <td>POLYGON ((995877.31827 203206.07494, 995968.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>10162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((997731.76075 219560.92215, 997641.94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>10119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((986038.66144 213051.06312, 986135.31...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    zipcode  population                                           geometry\n",
       "0     11436     18681.0  POLYGON ((1038098.25187 188138.38001, 1038141....\n",
       "1     11213     62426.0  POLYGON ((1001613.71296 186926.43952, 1002314....\n",
       "2     11212     83866.0  POLYGON ((1011174.27554 183696.33771, 1011373....\n",
       "3     11225     56527.0  POLYGON ((995908.36545 183617.61280, 996522.84...\n",
       "4     11218     72280.0  POLYGON ((991997.11343 176307.49586, 992042.79...\n",
       "..      ...         ...                                                ...\n",
       "258   10310     25003.0  POLYGON ((950767.50659 172848.96866, 950787.51...\n",
       "259   11693     11052.0  POLYGON ((1028453.99491 167153.40984, 1027813....\n",
       "260   11249     28481.0  POLYGON ((995877.31827 203206.07494, 995968.51...\n",
       "261   10162         0.0  POLYGON ((997731.76075 219560.92215, 997641.94...\n",
       "262   10119         0.0  POLYGON ((986038.66144 213051.06312, 986135.31...\n",
       "\n",
       "[263 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipcode = clean_zipcode_data('data/nyc_zipcodes.shp')\n",
    "zipcode.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dea2f1da9eaed5",
   "metadata": {},
   "source": [
    "# Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dbefcc832d105dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T01:55:53.627984200Z",
     "start_time": "2023-11-29T01:55:53.586770400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createdb: error: database creation failed: ERROR:  database \"FINAL_PROJECT\" already exists\n",
      "ERROR:  extension \"postgis\" already exists\n",
      "psql:schema.sql:7: ERROR:  type \"string\" does not exist\n",
      "LINE 3:                 neighborhood String,\n",
      "                                     ^\n",
      "psql:schema.sql:18: ERROR:  type \"string\" does not exist\n",
      "LINE 4:                 complaint_type String,\n",
      "                                       ^\n",
      "psql:schema.sql:29: ERROR:  type \"string\" does not exist\n",
      "LINE 3:                 species String,\n",
      "                                ^\n",
      "psql:schema.sql:35: ERROR:  relation \"average_rents\" already exists\n"
     ]
    }
   ],
   "source": [
    "!createdb FINAL_PROJECT\n",
    "!psql --dbname FINAL_PROJECT -c 'CREATE EXTENSION postgis;'\n",
    "!psql --dbname FINAL_PROJECT -f schema.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63488583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T03:08:38.188433400Z",
     "start_time": "2023-11-29T03:08:38.174506500Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "796567f058261f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T03:08:38.424507500Z",
     "start_time": "2023-11-29T03:08:38.354942700Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=FINAL_PROJECT user=postgres password=123456\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e4743c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nyc_zipcodes_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS nyc_zip_codes (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        zipcode INTEGER NOT NULL,\n",
    "        population INTEGER,\n",
    "        geometry POINT\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17f2b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_311_complaints_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS complaints311 (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        created_date DATE,\n",
    "        closed_date DATE,\n",
    "        agency VARCHAR,\n",
    "        complaint_type VARCHAR,\n",
    "        descriptor VARCHAR,\n",
    "        location_type VARCHAR,\n",
    "        incident_zip INTEGER,\n",
    "        latitude FLOAT,\n",
    "        longitude FLOAT,\n",
    "        borough VARCHAR,\n",
    "        geometry POINT\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2e657cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_trees_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tree_census_2015 (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        geometry geometry(Geometry, 4326),\n",
    "        status VARCHAR,\n",
    "        health VARCHAR,\n",
    "        species VARCHAR,\n",
    "        zipcode INTEGER,\n",
    "        borough VARCHAR,\n",
    "        latitude FLOAT,\n",
    "        longitude FLOAT\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "03829280",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_zillow_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS zillow_rents(\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        zipcode INTEGER,\n",
    "        county VARCHAR,\n",
    "        other_columns FLOAT\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2c0af8c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the query contains more than one '%s' placeholder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/98/l9_9vlzx4vs8g303whfvnnjc0000gn/T/ipykernel_22407/2358937363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mVALUES\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mST_GeomFromText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4326\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \"\"\"\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mextras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_to_insert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Commit the changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m     \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36m_split_sql\u001b[0;34m(sql)\u001b[0m\n\u001b[1;32m   1322\u001b[0m                 \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1325\u001b[0m                     \"the query contains more than one '%s' placeholder\")\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'%'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: the query contains more than one '%s' placeholder"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "from shapely import wkt  # Import the Well-Known Text (WKT) module from Shapely\n",
    "\n",
    "# Assuming you have a function clean_tree_data that reads and processes the CSV\n",
    "gdf = clean_tree_data('data/tree_data.csv')\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\"dbname=FINAL_PROJECT user=postgres password=123456\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Define the table schema\n",
    "create_trees_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tree_census_2015 (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        geometry geometry(Point, 4326),\n",
    "        status VARCHAR,\n",
    "        health VARCHAR,\n",
    "        species VARCHAR,\n",
    "        zipcode INTEGER,\n",
    "        borough VARCHAR,\n",
    "        latitude FLOAT,\n",
    "        longitude FLOAT\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(create_trees_table)\n",
    "conn.commit()\n",
    "gdf=clean_tree_data('data/tree_data.csv')\n",
    "# Prepare data for insertion\n",
    "data_to_insert = [(wkt.dumps(row.geometry), row.status, row.health, row.species, row.zipcode, row.borough, row.latitude, row.longitude)\n",
    "                  for row in gdf.itertuples(index=False)]\n",
    "\n",
    "# Insert data into the table\n",
    "insert_query = \"\"\"\n",
    "    INSERT INTO tree_census_2015 (geometry, status, health, species, zipcode, borough, latitude, longitude)\n",
    "    VALUES (ST_GeomFromText(%s, 4326), %s, %s, %s, %s,%s, %s, %s);\n",
    "\"\"\"\n",
    "extras.execute_values(cur, insert_query, data_to_insert, template=None, page_size=100)\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e904cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: the query contains more than one '%s' placeholder\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import psycopg2.extras as extras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def insert_data_into_postgres(conn, df, table):\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = ','.join(list(df.columns))\n",
    "    placeholders = ','.join(['%s'] * len(df.columns))\n",
    "\n",
    "    query = f\"INSERT INTO {table} ({cols}) VALUES ({placeholders})\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "        print(\"The DataFrame is inserted.\")\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error:\", error)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=FINAL_PROJECT user=postgres password=123456\")\n",
    "\n",
    "df = clean_tree_data('data/tree_data.csv')\n",
    "\n",
    "insert_data_into_postgres(conn, df, 'tree_census_2015')\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b9ddeb7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "syntax error at or near \"\\\"\nLINE 1: \\COPY zillow_rents(zipcode, county, other_columns) FROM 'dat...\n        ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/98/l9_9vlzx4vs8g303whfvnnjc0000gn/T/ipykernel_22407/3842019700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_zillow_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0minsert_zillow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"\\COPY zillow_rents(zipcode, county, other_columns) FROM 'data/zillow_rent_data.csv' DELIMITER ',' CSV HEADER;\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_zillow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mzillow3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"SELECT * FROM zillow_rents;\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzillow3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: syntax error at or near \"\\\"\nLINE 1: \\COPY zillow_rents(zipcode, county, other_columns) FROM 'dat...\n        ^\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "conn = psycopg2.connect(\"dbname=FINAL_PROJECT user=postgres password=123456\")\n",
    "cur = conn.cursor()\n",
    "create_zillow_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS zillow_rents(\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        zipcode INTEGER,\n",
    "        county VARCHAR,\n",
    "        other_columns FLOAT\n",
    "    );\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "67f38b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(create_nyc_zipcodes_table)\n",
    "cur.execute(create_311_complaints_table)\n",
    "cur.execute(create_trees_table)\n",
    "cur.execute(create_zillow_table)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c33da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb09b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42c6bc5c024a8c2",
   "metadata": {},
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a02c5e133f921d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18ffd1bb99075ea9",
   "metadata": {},
   "source": [
    "# Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af7d548eed2ae8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-24T11:43:13.539677300Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
